# linear-algebra-for-machine-learning

## week 1 Key take aways ([link](https://github.com/hsarfraz/linear-algebra-for-machine-learning/blob/main/week%201/week%201%20lecture%20notes.md))
* dicriminative vs. generative AI
* separation line, regression line, line of best fit, and perceptron
* perceptron line
* linearly separable vs. linear relationship


## week 2 Key take aways ([link](https://github.com/hsarfraz/linear-algebra-for-machine-learning/blob/main/week%202/week%202%20lecture%20notes.md))
* Defining a matrix (2D array), vector (1D or 2D array), and scalar (single number)
* Dot Product
* The Determinant ([Illustration of deteminant](https://www.youtube.com/watch?v=Ip3X9LOh2dk&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=8))

## week 3 Key take aways ([link](https://github.com/hsarfraz/linear-algebra-for-machine-learning/blob/main/week%203/notes.md))
* Gauss Jordan Elimination
* Using elementary row operations (ERO) in Gauss Jordan Elimination
* Augmented matrix
* Pivots
* Under determined Matrix System of Linear Equations
* Over determined Matrix System of Linear Equations
* Dependent Variables
* Free Variables
* Homogeneous system of linear equations
* Non-homogeneous system of linear equations
* Rank of a matrix after Gauss Jordan Elimination
* Trivial solutions of a system of linear equations
* Non-trivial solutions of a system of linear equations
* Moore Penrose Pseudo Inverse

## week 4 Key take aways ()
